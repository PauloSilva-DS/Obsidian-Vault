---
tags:
  - estudo
  - python
Completo: false
Atualizado: 2025-03-07  15.08
Criado: 2025-03-07  15.07
---
[[üìö0 - Aprendizado de m√°quina]]


---

### **Parte I. Os Fundamentos do Aprendizado de M√°quina**

#### **Cap√≠tulo 1. O Panorama do Aprendizado de M√°quina**

H√° n√£o muito tempo, se voc√™ pegasse seu telefone e perguntasse o caminho para casa, ele provavelmente o ignoraria ‚Äî e as pessoas questionariam sua sanidade. Mas o aprendizado de m√°quina n√£o √© mais fic√ß√£o cient√≠fica: bilh√µes de pessoas o usam todos os dias. E a verdade √© que ele j√° existe h√° d√©cadas em algumas aplica√ß√µes especializadas, como o reconhecimento √≥ptico de caracteres (OCR). A primeira aplica√ß√£o de aprendizado de m√°quina que realmente se tornou popular, melhorando a vida de centenas de milh√µes de pessoas, conquistou o mundo nos anos 1990: o **filtro de spam**. N√£o √© exatamente um rob√¥ autoconsciente, mas tecnicamente se qualifica como aprendizado de m√°quina: ele realmente aprendeu t√£o bem que voc√™ raramente precisa marcar um e-mail como spam. Ele foi seguido por centenas de aplica√ß√µes de aprendizado de m√°quina que agora alimentam silenciosamente centenas de produtos e funcionalidades que voc√™ usa regularmente: comandos de voz, tradu√ß√£o autom√°tica, busca de imagens, recomenda√ß√µes de produtos e muito mais.

Onde come√ßa e onde termina o aprendizado de m√°quina? O que exatamente significa uma m√°quina aprender algo? Se eu baixar uma c√≥pia de todos os artigos da Wikipedia, meu computador realmente aprendeu algo? Ele ficou mais inteligente de repente? Neste cap√≠tulo, come√ßarei esclarecendo o que √© aprendizado de m√°quina e por que voc√™ pode querer us√°-lo.

Ent√£o, antes de explorarmos o continente do aprendizado de m√°quina, daremos uma olhada no mapa e aprenderemos sobre as principais regi√µes e os marcos mais not√°veis: aprendizado **supervisionado** versus **n√£o supervisionado** e suas variantes, aprendizado **online** versus **em lote**, aprendizado **baseado em inst√¢ncia** versus **baseado em modelo**. Depois, veremos o fluxo de trabalho t√≠pico de um projeto de aprendizado de m√°quina, discutiremos os principais desafios que voc√™ pode enfrentar e abordaremos como avaliar e ajustar um sistema de aprendizado de m√°quina.

Este cap√≠tulo introduz muitos conceitos fundamentais (e jarg√µes) que todo cientista de dados deve saber de cor. Ser√° uma vis√£o de alto n√≠vel (√© o √∫nico cap√≠tulo sem muito c√≥digo), tudo bastante simples, mas meu objetivo √© garantir que tudo esteja cristalino para voc√™ antes de continuarmos com o restante do livro. Ent√£o, pegue um caf√© e vamos come√ßar!

**DICA**  
Se voc√™ j√° est√° familiarizado com os conceitos b√°sicos de aprendizado de m√°quina, pode pular diretamente para o Cap√≠tulo 2. Se n√£o tem certeza, tente responder a todas as perguntas listadas no final do cap√≠tulo antes de prosseguir.

---

#### **O Que √â Aprendizado de M√°quina?**

Aprendizado de m√°quina √© a ci√™ncia (e arte) de programar computadores para que eles possam aprender com dados.

Aqui est√° uma defini√ß√£o um pouco mais geral:

> [Aprendizado de m√°quina √© o] campo de estudo que d√° aos computadores a capacidade de aprender sem serem explicitamente programados.  
> ‚Äî Arthur Samuel, 1959

E uma defini√ß√£o mais orientada para a engenharia:

> Um programa de computador √© dito aprender com a experi√™ncia \( E \) em rela√ß√£o a alguma tarefa \( T \) e alguma medida de desempenho \( P \), se seu desempenho em \( T \), medido por \( P \), melhorar com a experi√™ncia \( E \).  
> ‚Äî Tom Mitchell, 1997

Seu filtro de spam √© um programa de aprendizado de m√°quina que, dados exemplos de e-mails de spam (marcados pelos usu√°rios) e exemplos de e-mails regulares (n√£o spam, tamb√©m chamados de "ham"), pode aprender a marcar spam. Os exemplos que o sistema usa para aprender s√£o chamados de **conjunto de treinamento**. Cada exemplo de treinamento √© chamado de **inst√¢ncia de treinamento** (ou amostra). A parte de um sistema de aprendizado de m√°quina que aprende e faz previs√µes √© chamada de **modelo**. Redes neurais e florestas aleat√≥rias s√£o exemplos de modelos.

Neste caso, a tarefa \( T \) √© marcar spam para novos e-mails, a experi√™ncia \( E \) s√£o os dados de treinamento, e a medida de desempenho \( P \) precisa ser definida; por exemplo, voc√™ pode usar a propor√ß√£o de e-mails classificados corretamente. Essa medida de desempenho em particular √© chamada de **acur√°cia**, e √© frequentemente usada em tarefas de classifica√ß√£o.

Se voc√™ simplesmente baixar uma c√≥pia de todos os artigos da Wikipedia, seu computador ter√° muito mais dados, mas n√£o ficar√° subitamente melhor em nenhuma tarefa. Isso n√£o √© aprendizado de m√°quina.

---

#### **Por Que Usar Aprendizado de M√°quina?**

Considere como voc√™ escreveria um filtro de spam usando t√©cnicas de programa√ß√£o tradicionais (Figura 1-1):

1. Primeiro, voc√™ examinaria como o spam geralmente se parece. Voc√™ pode notar que algumas palavras ou frases (como "4U", "cart√£o de cr√©dito", "gr√°tis" e "incr√≠vel") tendem a aparecer muito na linha de assunto. Talvez voc√™ tamb√©m notasse alguns outros padr√µes no nome do remetente, no corpo do e-mail e em outras partes do e-mail.
2. Voc√™ escreveria um algoritmo de detec√ß√£o para cada um dos padr√µes que notou, e seu programa marcaria e-mails como spam se v√°rios desses padr√µes fossem detectados.
3. Voc√™ testaria seu programa e repetiria os passos 1 e 2 at√© que ele estivesse bom o suficiente para ser lan√ßado.

**Figura 1-1. A abordagem tradicional**  
Como o problema √© dif√≠cil, seu programa provavelmente se tornar√° uma longa lista de regras complexas ‚Äî bastante dif√≠cil de manter.

Em contraste, um filtro de spam baseado em t√©cnicas de aprendizado de m√°quina aprende automaticamente quais palavras e frases s√£o bons preditores de spam, detectando padr√µes incomuns de palavras nos exemplos de spam em compara√ß√£o com os exemplos de ham (Figura 1-2). O programa √© muito mais curto, f√°cil de manter e, muito provavelmente, mais preciso.

**Figura 1-2. A abordagem de aprendizado de m√°quina**  
E se os spammers perceberem que todos os seus e-mails contendo "4U" s√£o bloqueados? Eles podem come√ßar a escrever "For U" em vez disso. Um filtro de spam usando t√©cnicas de programa√ß√£o tradicionais precisaria ser atualizado para marcar e-mails com "For U". Se os spammers continuarem contornando seu filtro de spam, voc√™ precisar√° continuar escrevendo novas regras para sempre.

Em contraste, um filtro de spam baseado em t√©cnicas de aprendizado de m√°quina percebe automaticamente que "For U" se tornou incomumente frequente nos spams marcados pelos usu√°rios e come√ßa a marc√°-los sem sua interven√ß√£o (Figura 1-3).

**Figura 1-3. Adaptando-se automaticamente √†s mudan√ßas**  
Outra √°rea onde o aprendizado de m√°quina se destaca √© para problemas que s√£o muito complexos para abordagens tradicionais ou para os quais n√£o h√° algoritmo conhecido. Por exemplo, considere o reconhecimento de fala. Digamos que voc√™ queira come√ßar de forma simples e escrever um programa capaz de distinguir as palavras "um" e "dois". Voc√™ pode notar que a palavra "dois" come√ßa com um som agudo ("T"), ent√£o voc√™ poderia codificar um algoritmo que mede a intensidade do som agudo e us√°-lo para distinguir "um" e "dois" ‚Äî mas, obviamente, essa t√©cnica n√£o escalaria para milhares de palavras faladas por milh√µes de pessoas muito diferentes em ambientes ruidosos e em dezenas de idiomas. A melhor solu√ß√£o (pelo menos hoje) √© escrever um algoritmo que aprenda sozinho, dados muitos exemplos de grava√ß√µes para cada palavra.

Finalmente, o aprendizado de m√°quina pode ajudar os humanos a aprender (Figura 1-4). Modelos de aprendizado de m√°quina podem ser inspecionados para ver o que aprenderam (embora, para alguns modelos, isso possa ser complicado). Por exemplo, uma vez que um filtro de spam foi treinado com spam suficiente, ele pode ser facilmente inspecionado para revelar a lista de palavras e combina√ß√µes de palavras que ele acredita serem os melhores preditores de spam. √Äs vezes, isso revelar√° correla√ß√µes inesperadas ou novas tend√™ncias, levando a uma melhor compreens√£o do problema. Cavar grandes quantidades de dados para descobrir padr√µes ocultos √© chamado de **minera√ß√£o de dados**, e o aprendizado de m√°quina se destaca nisso.

**Figura 1-4. O aprendizado de m√°quina pode ajudar os humanos a aprender**  
Para resumir, o aprendizado de m√°quina √© √≥timo para:
- **Problemas para os quais as solu√ß√µes existentes exigem muito ajuste fino ou longas listas de regras**: um modelo de aprendizado de m√°quina pode simplificar o c√≥digo e ter um desempenho melhor que a abordagem tradicional.
- **Problemas complexos para os quais o uso de uma abordagem tradicional n√£o oferece uma boa solu√ß√£o**: as melhores t√©cnicas de aprendizado de m√°quina podem talvez encontrar uma solu√ß√£o.
- **Ambientes flutuantes**: um sistema de aprendizado de m√°quina pode ser facilmente retreinado com novos dados, mantendo-se sempre atualizado.
- **Obter insights sobre problemas complexos e grandes quantidades de dados**.

---

#### **Exemplos de Aplica√ß√µes**

Vejamos alguns exemplos concretos de tarefas de aprendizado de m√°quina, juntamente com as t√©cnicas que podem resolv√™-las:

- **Analisar imagens de produtos em uma linha de produ√ß√£o para classific√°-los automaticamente**:  
  Isso √© **classifica√ß√£o de imagens**, tipicamente realizada usando redes neurais convolucionais (CNNs; veja o Cap√≠tulo 14) ou, √†s vezes, transformadores (veja o Cap√≠tulo 16).

- **Detectar tumores em exames cerebrais**:  
  Isso √© **segmenta√ß√£o sem√¢ntica de imagens**, onde cada pixel na imagem √© classificado (pois queremos determinar a localiza√ß√£o exata e a forma dos tumores), tipicamente usando CNNs ou transformadores.

- **Classificar automaticamente artigos de not√≠cias**:  
  Isso √© **processamento de linguagem natural (NLP)** e, mais especificamente, **classifica√ß√£o de texto**, que pode ser abordada usando redes neurais recorrentes (RNNs) e CNNs, mas os transformadores funcionam ainda melhor (veja o Cap√≠tulo 16).

- **Sinalizar automaticamente coment√°rios ofensivos em f√≥runs de discuss√£o**:  
  Isso tamb√©m √© **classifica√ß√£o de texto**, usando as mesmas ferramentas de NLP.

- **Resumir automaticamente documentos longos**:  
  Isso √© uma ramifica√ß√£o do NLP chamada **sumariza√ß√£o de texto**, novamente usando as mesmas ferramentas.

- **Criar um chatbot ou um assistente pessoal**:  
  Isso envolve muitos componentes de NLP, incluindo m√≥dulos de **compreens√£o de linguagem natural (NLU)** e de **resposta a perguntas**.

- **Prever a receita da sua empresa no pr√≥ximo ano, com base em muitas m√©tricas de desempenho**:  
  Isso √© uma tarefa de **regress√£o** (ou seja, prever valores) que pode ser abordada usando qualquer modelo de regress√£o, como um modelo de regress√£o linear ou polinomial (veja o Cap√≠tulo 4), uma m√°quina de vetores de suporte para regress√£o (veja o Cap√≠tulo 5), uma floresta aleat√≥ria para regress√£o (veja o Cap√≠tulo 7) ou uma rede neural artificial (veja o Cap√≠tulo 10). Se voc√™ quiser levar em considera√ß√£o sequ√™ncias de m√©tricas de desempenho passadas, pode usar RNNs, CNNs ou transformadores (veja os Cap√≠tulos 15 e 16).

- **Fazer seu aplicativo reagir a comandos de voz**:  
  Isso √© **reconhecimento de fala**, que requer o processamento de amostras de √°udio: como s√£o sequ√™ncias longas e complexas, s√£o tipicamente processadas usando RNNs, CNNs ou transformadores (veja os Cap√≠tulos 15 e 16).

- **Detectar fraudes em cart√µes de cr√©dito**:  
  Isso √© **detec√ß√£o de anomalias**, que pode ser abordada usando florestas de isolamento, modelos de mistura gaussiana (veja o Cap√≠tulo 9) ou autoencoders (veja o Cap√≠tulo 17).

- **Segmentar clientes com base em suas compras para que voc√™ possa projetar uma estrat√©gia de marketing diferente para cada segmento**:  
  Isso √© **clustering**, que pode ser alcan√ßado usando \( k \)-means, DBSCAN e outros (veja o Cap√≠tulo 9).

- **Representar um conjunto de dados complexo e de alta dimensionalidade em um diagrama claro e perspicaz**:  
  Isso √© **visualiza√ß√£o de dados**, muitas vezes envolvendo t√©cnicas de redu√ß√£o de dimensionalidade (veja o Cap√≠tulo 8).

- **Recomendar um produto que um cliente pode estar interessado, com base em compras anteriores**:  
  Isso √© um **sistema de recomenda√ß√£o**. Uma abordagem √© alimentar as compras anteriores (e outras informa√ß√µes sobre o cliente) em uma rede neural artificial (veja o Cap√≠tulo 10) e faz√™-la prever a pr√≥xima compra mais prov√°vel. Essa rede neural seria tipicamente treinada em sequ√™ncias passadas de compras de todos os clientes.

- **Construir um bot inteligente para um jogo**:  
  Isso √© frequentemente abordado usando **aprendizado por refor√ßo (RL; veja o Cap√≠tulo 18)**, que √© um ramo do aprendizado de m√°quina que treina agentes (como bots) para escolher as a√ß√µes que maximizar√£o suas recompensas ao longo do tempo (por exemplo, um bot pode receber uma recompensa toda vez que o jogador perder pontos de vida), dentro de um determinado ambiente (como o jogo). O famoso programa AlphaGo, que derrotou o campe√£o mundial no jogo Go, foi constru√≠do usando RL.

Essa lista poderia continuar, mas espero que ela d√™ uma ideia da incr√≠vel amplitude e complexidade das tarefas que o aprendizado de m√°quina pode abordar e dos tipos de t√©cnicas que voc√™ usaria para cada tarefa.

---

#### **Tipos de Sistemas de Aprendizado de M√°quina**

Existem tantos tipos diferentes de sistemas de aprendizado de m√°quina que √© √∫til classific√°-los em categorias amplas, com base nos seguintes crit√©rios:

1. **Como eles s√£o supervisionados durante o treinamento**: supervisionado, n√£o supervisionado, semi-supervisionado, auto-supervisionado e outros.
2. **Se eles podem aprender incrementalmente em tempo real**: online versus em lote.
3. **Se eles funcionam simplesmente comparando novos pontos de dados a pontos de dados conhecidos ou, em vez disso, detectando padr√µes nos dados de treinamento e construindo um modelo preditivo, como cientistas fazem**: baseado em inst√¢ncia versus baseado em modelo.

Esses crit√©rios n√£o s√£o exclusivos; voc√™ pode combin√°-los da maneira que quiser. Por exemplo, um filtro de spam state-of-the-art pode aprender em tempo real usando um modelo de rede neural profunda treinado com exemplos de spam e ham fornecidos por humanos; isso o torna um sistema de aprendizado online, baseado em modelo e supervisionado.

Vamos examinar cada um desses crit√©rios mais de perto.

---

#### **Supervis√£o de Treinamento**

Os sistemas de aprendizado de m√°quina podem ser classificados de acordo com a quantidade e o tipo de supervis√£o que recebem durante o treinamento. Existem muitas categorias, mas discutiremos as principais: aprendizado supervisionado, n√£o supervisionado, auto-supervisionado, semi-supervisionado e aprendizado por refor√ßo.

---

#### **Aprendizado Supervisionado**

No aprendizado supervisionado, o conjunto de treinamento que voc√™ alimenta ao algoritmo inclui as solu√ß√µes desejadas, chamadas de **r√≥tulos** (Figura 1-5).

**Figura 1-5. Um conjunto de treinamento rotulado para classifica√ß√£o de spam (um exemplo de aprendizado supervisionado)**

Uma tarefa t√≠pica de aprendizado supervisionado √© a **classifica√ß√£o**. O filtro de spam √© um bom exemplo disso: ele √© treinado com muitos exemplos de e-mails junto com sua classe (spam ou ham), e ele deve aprender como classificar novos e-mails.

Outra tarefa t√≠pica √© prever um valor num√©rico, como o pre√ßo de um carro, dado um conjunto de caracter√≠sticas (quilometragem, idade, marca, etc.). Esse tipo de tarefa √© chamado de **regress√£o** (Figura 1-6). Para treinar o sistema, voc√™ precisa fornecer muitos exemplos de carros, incluindo suas caracter√≠sticas e seus valores alvo (ou seja, seus pre√ßos).

**Figura 1-6. Um problema de regress√£o: prever um valor, dado um recurso de entrada (geralmente h√° v√°rios recursos de entrada e, √†s vezes, v√°rios valores de sa√≠da)**

**NOTA**  
As palavras **target** e **label** s√£o geralmente tratadas como sin√¥nimos em aprendizado supervisionado, mas **target** √© mais comum em tarefas de regress√£o e **label** √© mais comum em tarefas de classifica√ß√£o. Al√©m disso, **features** √†s vezes s√£o chamadas de **predictors** ou **attributes**. Esses termos podem se referir a amostras individuais (por exemplo, "a quilometragem deste carro √© 15.000") ou a todas as amostras (por exemplo, "a quilometragem est√° fortemente correlacionada com o pre√ßo").

---

#### **Aprendizado N√£o Supervisionado**

No aprendizado n√£o supervisionado, como voc√™ pode imaginar, os dados de treinamento n√£o s√£o rotulados (Figura 1-7). O sistema tenta aprender sem um professor.

**Figura 1-7. Um conjunto de treinamento n√£o rotulado para aprendizado n√£o supervisionado**

Por exemplo, digamos que voc√™ tenha muitos dados sobre os visitantes do seu blog. Voc√™ pode querer executar um algoritmo de **clustering** para tentar detectar grupos de visitantes semelhantes (Figura 1-8). Em nenhum momento voc√™ diz ao algoritmo a qual grupo um visitante pertence: ele encontra essas conex√µes sem sua ajuda. Por exemplo, ele pode notar que 40% dos seus visitantes s√£o adolescentes que adoram quadrinhos e geralmente leem seu blog ap√≥s a escola, enquanto 20% s√£o adultos que gostam de fic√ß√£o cient√≠fica e visitam durante os fins de semana. Se voc√™ usar um algoritmo de clustering hier√°rquico, ele tamb√©m pode subdividir cada grupo em grupos menores. Isso pode ajud√°-lo a direcionar suas postagens para cada grupo.

**Figura 1-8. Clustering**

Algoritmos de **visualiza√ß√£o** tamb√©m s√£o bons exemplos de aprendizado n√£o supervisionado: voc√™ os alimenta com muitos dados complexos e n√£o rotulados, e eles produzem uma representa√ß√£o 2D ou 3D dos seus dados que pode ser facilmente plotada (Figura 1-9). Esses algoritmos tentam preservar o m√°ximo de estrutura poss√≠vel (por exemplo, tentando evitar que clusters separados no espa√ßo de entrada se sobreponham na visualiza√ß√£o) para que voc√™ possa entender como os dados est√£o organizados e talvez identificar padr√µes inesperados.

**Figura 1-9. Exemplo de uma visualiza√ß√£o t-SNE destacando clusters sem√¢nticos**

**DICA**  
√â frequentemente uma boa ideia tentar reduzir o n√∫mero de dimens√µes nos seus dados de treinamento usando um algoritmo de redu√ß√£o de dimensionalidade antes de aliment√°-los a outro algoritmo de aprendizado de m√°quina (como um algoritmo de aprendizado supervisionado). Ele rodar√° muito mais r√°pido, os dados ocupar√£o menos espa√ßo em disco e na mem√≥ria, e em alguns casos tamb√©m pode ter um desempenho melhor.

Outra tarefa importante de aprendizado n√£o supervisionado √© a **detec√ß√£o de anomalias** ‚Äî por exemplo, detectar transa√ß√µes incomuns de cart√£o de cr√©dito para prevenir fraudes, capturar defeitos de fabrica√ß√£o ou remover automaticamente outliers de um conjunto de dados antes de aliment√°-lo a outro algoritmo de aprendizado. O sistema √© mostrado principalmente inst√¢ncias normais durante o treinamento, ent√£o ele aprende a reconhec√™-las; depois, quando v√™ uma nova inst√¢ncia, ele pode dizer se ela parece normal ou se √© provavelmente uma anomalia (veja a Figura 1-10). Uma tarefa muito semelhante √© a **detec√ß√£o de novidades**: ela visa detectar novas inst√¢ncias que parecem diferentes de todas as inst√¢ncias no conjunto de treinamento. Isso requer ter um conjunto de treinamento muito "limpo", sem nenhuma inst√¢ncia que voc√™ gostaria que o algoritmo detectasse. Por exemplo, se voc√™ tiver milhares de fotos de cachorros, e 1% dessas fotos representam Chihuahuas, ent√£o um algoritmo de detec√ß√£o de novidades n√£o deve tratar novas fotos de Chihuahuas como novidades. Por outro lado, algoritmos de detec√ß√£o de anomalias podem considerar esses cachorros t√£o raros e diferentes de outros cachorros que provavelmente os classificariam como anomalias (sem ofensa aos Chihuahuas).

**Figura 1-10. Detec√ß√£o de anomalias**

Finalmente, outra tarefa comum de aprendizado n√£o supervisionado √© a **aprendizagem de regras de associa√ß√£o**, na qual o objetivo √© cavar grandes quantidades de dados e descobrir rela√ß√µes interessantes entre atributos. Por exemplo, suponha que voc√™ tenha um supermercado. Executar uma regra de associa√ß√£o nos seus registros de vendas pode revelar que pessoas que compram molho barbecue e batatas fritas tamb√©m tendem a comprar bife. Assim, voc√™ pode querer colocar esses itens pr√≥ximos uns dos outros.

---

#### **Aprendizado Semi-Supervisionado**

Como rotular dados geralmente consome tempo e √© caro, muitas vezes voc√™ ter√° muitas inst√¢ncias n√£o rotuladas e poucas inst√¢ncias rotuladas. Alguns algoritmos podem lidar com dados parcialmente rotulados. Isso √© chamado de **aprendizado semi-supervisionado** (Figura 1-11).

**Figura 1-11. Aprendizado semi-supervisionado com duas classes (tri√¢ngulos e quadrados): os exemplos n√£o rotulados (c√≠rculos) ajudam a classificar uma nova inst√¢ncia (a cruz) na classe dos tri√¢ngulos em vez da classe dos quadrados, mesmo que ela esteja mais pr√≥xima dos quadrados rotulados**

Alguns servi√ßos de hospedagem de fotos, como o Google Fotos, s√£o bons exemplos disso. Depois que voc√™ faz o upload de todas as suas fotos de fam√≠lia para o servi√ßo, ele reconhece automaticamente que a mesma pessoa A aparece nas fotos 1, 5 e 11, enquanto outra pessoa B aparece nas fotos 2, 5 e 7. Essa √© a parte n√£o supervisionada do algoritmo (clustering). Agora, tudo o que o sistema precisa √© que voc√™ diga quem s√£o essas pessoas. Basta adicionar um r√≥tulo por pessoa\(^3\), e ele ser√° capaz de nomear todos em todas as fotos, o que √© √∫til para pesquisar fotos.

A maioria dos algoritmos de aprendizado semi-supervisionado s√£o combina√ß√µes de algoritmos n√£o supervisionados e supervisionados. Por exemplo, um algoritmo de clustering pode ser usado para agrupar inst√¢ncias semelhantes, e ent√£o cada inst√¢ncia n√£o rotulada pode ser rotulada com o r√≥tulo mais comum em seu cluster. Depois que todo o conjunto de dados √© rotulado, √© poss√≠vel usar qualquer algoritmo de aprendizado supervisionado.

---

#### **Aprendizado Auto-Supervisionado**

Outra abordagem para o aprendizado de m√°quina envolve gerar um conjunto de dados totalmente rotulado a partir de um conjunto de dados n√£o rotulado. Novamente, uma vez que todo o conjunto de dados √© rotulado, qualquer algoritmo de aprendizado supervisionado pode ser usado. Essa abordagem √© chamada de **aprendizado auto-supervisionado**.

Por exemplo, se voc√™ tiver um grande conjunto de dados de imagens n√£o rotuladas, pode mascarar aleatoriamente uma pequena parte de cada imagem e ent√£o treinar um modelo para recuperar a imagem original (Figura 1-12). Durante o treinamento, as imagens mascaradas s√£o usadas como entradas para o modelo, e as imagens originais s√£o usadas como r√≥tulos.

**Figura 1-12. Exemplo de aprendizado auto-supervisionado: entrada (esquerda) e alvo (direita)**

O modelo resultante pode ser bastante √∫til por si s√≥ ‚Äî por exemplo, para reparar imagens danificadas ou para apagar objetos indesejados de fotos. Mas, na maioria das vezes, um modelo treinado com aprendizado auto-supervisionado n√£o √© o objetivo final. Voc√™ geralmente desejar√° ajustar e refinar o modelo para uma tarefa ligeiramente diferente ‚Äî uma que voc√™ realmente se importa.

Por exemplo, suponha que o que voc√™ realmente deseja √© ter um modelo de classifica√ß√£o de animais de estima√ß√£o: dada uma foto de qualquer animal de estima√ß√£o, ele dir√° a qual esp√©cie ele pertence. Se voc√™ tiver um grande conjunto de dados de fotos n√£o rotuladas de animais de estima√ß√£o, pode come√ßar treinando um modelo de repara√ß√£o de imagens usando aprendizado auto-supervisionado. Uma vez que ele estiver funcionando bem, ele deve ser capaz de distinguir diferentes esp√©cies de animais de estima√ß√£o: quando ele repara uma imagem de um gato cujo rosto est√° mascarado, ele deve saber n√£o adicionar o rosto de um cachorro. Supondo que a arquitetura do seu modelo permita isso (e a maioria das arquiteturas de redes neurais permite), √© poss√≠vel ajustar o modelo para que ele preveja esp√©cies de animais de estima√ß√£o em vez de reparar imagens. O passo final consiste em ajustar o modelo em um conjunto de dados rotulado: o modelo j√° sabe como s√£o gatos, cachorros e outras esp√©cies de animais de estima√ß√£o, ent√£o este passo √© necess√°rio apenas para que o modelo aprenda o mapeamento entre as esp√©cies que ele j√° conhece e os r√≥tulos que esperamos dele.

**NOTA**  
Transferir conhecimento de uma tarefa para outra √© chamado de **aprendizado por transfer√™ncia (transfer learning)**, e √© uma das t√©cnicas mais importantes no aprendizado de m√°quina hoje, especialmente ao usar redes neurais profundas (ou seja, redes neurais compostas por muitas camadas de neur√¥nios). Discutiremos isso em detalhes na Parte II.

Algumas pessoas consideram o aprendizado auto-supervisionado como parte do aprendizado n√£o supervisionado, j√° que ele lida com conjuntos de dados totalmente n√£o rotulados. Mas o aprendizado auto-supervisionado usa r√≥tulos (gerados) durante o treinamento, ent√£o, nesse aspecto, ele est√° mais pr√≥ximo do aprendizado supervisionado. E o termo "aprendizado n√£o supervisionado" √© geralmente usado ao lidar com tarefas como clustering, redu√ß√£o de dimensionalidade ou detec√ß√£o de anomalias, enquanto o aprendizado auto-supervisionado se concentra nas mesmas tarefas que o aprendizado supervisionado: principalmente classifica√ß√£o e regress√£o. Em resumo, √© melhor tratar o aprendizado auto-supervisionado como sua pr√≥pria categoria.

---

#### **Aprendizado por Refor√ßo**

O **aprendizado por refor√ßo** √© uma abordagem muito diferente. O sistema de aprendizado, chamado de **agente** nesse contexto, pode observar o ambiente, selecionar e executar a√ß√µes, e receber recompensas em troca (ou penalidades na forma de recompensas negativas, como mostrado na Figura 1-13). Ele deve ent√£o aprender por si mesmo qual √© a melhor estrat√©gia, chamada de **pol√≠tica**, para obter a maior recompensa ao longo do tempo. Uma pol√≠tica define qual a√ß√£o o agente deve escolher quando est√° em uma determinada situa√ß√£o.

**Figura 1-13. Aprendizado por refor√ßo**

Por exemplo, muitos rob√¥s implementam algoritmos de aprendizado por refor√ßo para aprender a andar. O programa AlphaGo da DeepMind tamb√©m √© um bom exemplo de aprendizado por refor√ßo: ele ganhou as manchetes em maio de 2017 quando derrotou Ke Jie, o jogador n√∫mero um do mundo na √©poca, no jogo Go. Ele aprendeu sua pol√≠tica vencedora analisando milh√µes de jogos e, em seguida, jogando muitos jogos contra si mesmo. Observe que o aprendizado foi desativado durante os jogos contra o campe√£o; o AlphaGo estava apenas aplicando a pol√≠tica que havia aprendido. Como voc√™ ver√° na pr√≥xima se√ß√£o, isso √© chamado de **aprendizado offline**.

---

#### **Aprendizado em Lote versus Online**

Outro crit√©rio usado para classificar sistemas de aprendizado de m√°quina √© se o sistema pode aprender incrementalmente a partir de um fluxo de dados recebidos.

---

#### **Aprendizado em Lote**

No **aprendizado em lote**, o sistema √© incapaz de aprender incrementalmente: ele deve ser treinado usando todos os dados dispon√≠veis. Isso geralmente levar√° muito tempo e recursos computacionais, ent√£o √© tipicamente feito offline. Primeiro, o sistema √© treinado e, em seguida, √© lan√ßado em produ√ß√£o e roda sem aprender mais; ele apenas aplica o que aprendeu. Isso √© chamado de **aprendizado offline**.

Infelizmente, o desempenho de um modelo tende a decair lentamente ao longo do tempo, simplesmente porque o mundo continua a evoluir enquanto o modelo permanece inalterado. Esse fen√¥meno √© frequentemente chamado de **decaimento do modelo** ou **deriva de dados**. A solu√ß√£o √© retreinar regularmente o modelo com dados atualizados. Com que frequ√™ncia voc√™ precisa fazer isso depende do caso de uso: se o modelo classifica fotos de gatos e cachorros, seu desempenho decair√° muito lentamente, mas se o modelo lida com sistemas que evoluem rapidamente, por exemplo, fazendo previs√µes no mercado financeiro, √© prov√°vel que ele decaia rapidamente.

**AVISO**  
Mesmo um modelo treinado para classificar fotos de gatos e cachorros pode precisar ser retreinado regularmente, n√£o porque gatos e cachorros v√£o sofrer muta√ß√µes da noite para o dia, mas porque as c√¢meras continuam mudando, juntamente com formatos de imagem, nitidez, brilho e propor√ß√µes de tamanho. Al√©m disso, as pessoas podem amar ra√ßas diferentes no pr√≥ximo ano, ou podem decidir vestir seus animais de estima√ß√£o com pequenos chap√©us ‚Äî quem sabe?

Se voc√™ quiser que um sistema de aprendizado em lote saiba sobre novos dados (como um novo tipo de spam), precisar√° treinar uma nova vers√£o do sistema do zero no conjunto completo de dados (n√£o apenas os novos dados, mas tamb√©m os dados antigos), e ent√£o substituir o modelo antigo pelo novo. Felizmente, todo o processo de treinamento, avalia√ß√£o e lan√ßamento de um sistema de aprendizado de m√°quina pode ser automatizado com relativa facilidade (como vimos na Figura 1-3), ent√£o mesmo um sistema de aprendizado em lote pode se adaptar √† mudan√ßa. Basta atualizar os dados e treinar uma nova vers√£o do sistema do zero quantas vezes for necess√°rio.

---

#### **Aprendizado Online**

No **aprendizado online**, voc√™ treina o sistema incrementalmente, alimentando-o com inst√¢ncias de dados sequencialmente, individualmente ou em pequenos grupos chamados **mini-lotes**. Cada passo de aprendizado √© r√°pido e barato, ent√£o o sistema pode aprender sobre novos dados em tempo real, √† medida que eles chegam (veja a Figura 1-14).

**Figura 1-14. No aprendizado online, um modelo √© treinado e lan√ßado em produ√ß√£o, e ent√£o continua aprendendo √† medida que novos dados chegam**

O aprendizado online √© √∫til para sistemas que precisam se adaptar a mudan√ßas extremamente r√°pidas (por exemplo, para detectar novos padr√µes no mercado de a√ß√µes). Tamb√©m √© uma boa op√ß√£o se voc√™ tiver recursos computacionais limitados; por exemplo, se o modelo for treinado em um dispositivo m√≥vel.

Al√©m disso, algoritmos de aprendizado online podem ser usados para treinar modelos em grandes conjuntos de dados que n√£o cabem na mem√≥ria principal de uma m√°quina (isso √© chamado de **aprendizado fora do n√∫cleo**). O algoritmo carrega parte dos dados, executa um passo de treinamento nesses dados e repete o processo at√© que tenha processado todos os dados (veja a Figura 1-15).

**Figura 1-15. Usando aprendizado online para lidar com grandes conjuntos de dados**

Um par√¢metro importante dos sistemas de aprendizado online √© a velocidade com que eles devem se adaptar a mudan√ßas nos dados: isso √© chamado de **taxa de aprendizado**. Se voc√™ definir uma taxa de aprendizado alta, seu sistema se adaptar√° rapidamente a novos dados, mas tamb√©m tender√° a esquecer rapidamente os dados antigos (e voc√™ n√£o quer que um filtro de spam marque apenas os tipos mais recentes de spam que ele viu). Por outro lado, se voc√™ definir uma taxa de aprendizado baixa, o sistema ter√° mais in√©rcia; ou seja, ele aprender√° mais lentamente, mas tamb√©m ser√° menos sens√≠vel a ru√≠dos nos novos dados ou a sequ√™ncias de pontos de dados n√£o representativos (outliers).

**AVISO**  
O aprendizado fora do n√∫cleo geralmente √© feito offline (ou seja, n√£o no sistema ao vivo), ent√£o o termo "aprendizado online" pode ser confuso. Pense nele como **aprendizado incremental**.

Um grande desafio com o aprendizado online √© que, se dados ruins forem alimentados ao sistema, o desempenho do sistema pode cair, possivelmente rapidamente (dependendo da qualidade dos dados e da taxa de aprendizado). Se for um sistema ao vivo, seus clientes notar√£o. Por exemplo, dados ruins podem vir de um bug (por exemplo, um sensor com defeito em um rob√¥) ou de algu√©m tentando manipular o sistema (por exemplo, spammando um mecanismo de busca para tentar se classificar bem nos resultados de pesquisa). Para reduzir esse risco, voc√™ precisa monitorar seu sistema de perto e desligar o aprendizado prontamente (e possivelmente reverter para um estado anterior que funcionava) se detectar uma queda no desempenho. Voc√™ tamb√©m pode querer monitorar os dados de entrada e reagir a dados anormais; por exemplo, usando um algoritmo de detec√ß√£o de anomalias (veja o Cap√≠tulo 9).

---

#### **Aprendizado Baseado em Inst√¢ncia versus Baseado em Modelo**

Outra maneira de categorizar sistemas de aprendizado de m√°quina √© pela forma como eles **generalizam**. A maioria das tarefas de aprendizado de m√°quina envolve fazer previs√µes. Isso significa que, dado um n√∫mero de exemplos de treinamento, o sistema precisa ser capaz de fazer boas previs√µes para (generalizar para) exemplos que nunca viu antes. Ter uma boa medida de desempenho nos dados de treinamento √© bom, mas insuficiente; o verdadeiro objetivo √© ter um bom desempenho em novas inst√¢ncias.

Existem duas abordagens principais para a generaliza√ß√£o: **aprendizado baseado em inst√¢ncia** e **aprendizado baseado em modelo**.

---

#### **Aprendizado Baseado em Inst√¢ncia**

Possivelmente a forma mais trivial de aprendizado √© simplesmente aprender de cor. Se voc√™ fosse criar um filtro de spam dessa maneira, ele apenas marcaria todos os e-mails que s√£o id√™nticos a e-mails que j√° foram marcados pelos usu√°rios ‚Äî n√£o a pior solu√ß√£o, mas certamente n√£o a melhor.

Em vez de apenas marcar e-mails id√™nticos a e-mails de spam conhecidos, seu filtro de spam poderia ser programado para tamb√©m marcar e-mails que s√£o muito semelhantes a e-mails de spam conhecidos. Isso requer uma medida de similaridade entre dois e-mails. Uma medida de similaridade (muito b√°sica) entre dois e-mails poderia ser contar o n√∫mero de palavras que eles t√™m em comum. O sistema marcaria um e-mail como spam se ele tivesse muitas palavras em comum com um e-mail de spam conhecido.

Isso √© chamado de **aprendizado baseado em inst√¢ncia**: o sistema aprende os exemplos de cor e, em seguida, generaliza para novos casos usando uma medida de similaridade para compar√°-los aos exemplos aprendidos (ou a um subconjunto deles). Por exemplo, na Figura 1-16, a nova inst√¢ncia seria classificada como um tri√¢ngulo porque a maioria das inst√¢ncias mais semelhantes pertence a essa classe.

**Figura 1-16. Aprendizado baseado em inst√¢ncia**

---

#### **Aprendizado Baseado em Modelo e um Fluxo de Trabalho T√≠pico de Aprendizado de M√°quina**

Outra maneira de generalizar a partir de um conjunto de exemplos √© construir um **modelo** desses exemplos e, em seguida, usar esse modelo para fazer previs√µes. Isso √© chamado de **aprendizado baseado em modelo** (Figura 1-17).

**Figura 1-17. Aprendizado baseado em modelo**

Por exemplo, suponha que voc√™ queira saber se o dinheiro torna as pessoas mais felizes, ent√£o voc√™ baixa os dados do √çndice de Vida Melhor da OCDE e as estat√≠sticas do Banco Mundial sobre o produto interno bruto (PIB) per capita. Em seguida, voc√™ une as tabelas e as ordena por PIB per capita. A Tabela 1-1 mostra um trecho do que voc√™ obt√©m.

**Tabela 1-1. O dinheiro torna as pessoas mais felizes?**

| Pa√≠s         | PIB per capita (USD) | Satisfa√ß√£o com a vida |
|--------------|----------------------|-----------------------|
| Turquia      | 28.384               | 5,5                   |
| Hungria      | 31.008               | 5,6                   |
| Fran√ßa       | 42.026               | 6,5                   |
| Estados Unidos | 60.236               | 6,9                   |
| Nova Zel√¢ndia | 42.404               | 7,3                   |
| Austr√°lia    | 48.698               | 7,3                   |
| Dinamarca    | 55.938               | 7,6                   |

Vamos plotar os dados para esses pa√≠ses (Figura 1-18).

**Figura 1-18. Voc√™ v√™ uma tend√™ncia aqui?**

Parece haver uma tend√™ncia aqui! Embora os dados sejam **ruidosos** (ou seja, parcialmente aleat√≥rios), parece que a satisfa√ß√£o com a vida aumenta mais ou menos linearmente √† medida que o PIB per capita do pa√≠s aumenta. Ent√£o voc√™ decide modelar a satisfa√ß√£o com a vida como uma fun√ß√£o linear do PIB per capita. Esse passo √© chamado de **sele√ß√£o de modelo**: voc√™ selecionou um **modelo linear** de satisfa√ß√£o com a vida com apenas um atributo, o PIB per capita (Equa√ß√£o 1-1).

**Equa√ß√£o 1-1. Um modelo linear simples**

\[ \text{satisfa√ß√£o\_com\_a\_vida} = \theta_0 + \theta_1 \times \text{PIB\_per\_capita} \]

Esse modelo tem dois **par√¢metros do modelo**, \(\theta_0\) e \(\theta_1\). Ao ajustar esses par√¢metros, voc√™ pode fazer seu modelo representar qualquer fun√ß√£o linear, como mostrado na Figura 1-19.

**Figura 1-19. Alguns poss√≠veis modelos lineares**

Antes de usar seu modelo, voc√™ precisa definir os valores dos par√¢metros \(\theta_0\) e \(\theta_1\). Como voc√™ pode saber quais valores far√£o seu modelo ter o melhor desempenho? Para responder a essa pergunta, voc√™ precisa especificar uma medida de desempenho. Voc√™ pode definir uma **fun√ß√£o de utilidade** (ou **fun√ß√£o de aptid√£o**) que mede o qu√£o **bom** seu modelo √©, ou pode definir uma **fun√ß√£o de custo** que mede o qu√£o **ruim** ele √©. Para problemas de regress√£o linear, as pessoas geralmente usam uma fun√ß√£o de custo que mede a dist√¢ncia entre as previs√µes do modelo linear e os exemplos de treinamento; o objetivo √© minimizar essa dist√¢ncia.

√â a√≠ que entra o algoritmo de regress√£o linear: voc√™ o alimenta com seus exemplos de treinamento, e ele encontra os par√¢metros que fazem o modelo linear se ajustar melhor aos seus dados. Isso √© chamado de **treinamento** do modelo. No nosso caso, o algoritmo descobre que os valores √≥timos dos par√¢metros s√£o \(\theta_0 = 3,75\) e \(\theta_1 = 6,78 \times 10^{-5}\).

**AVISO**  
Confusamente, a palavra "modelo" pode se referir a um tipo de modelo (por exemplo, regress√£o linear), a uma arquitetura de modelo totalmente especificada (por exemplo, regress√£o linear com uma entrada e uma sa√≠da) ou ao modelo final treinado e pronto para ser usado para previs√µes (por exemplo, regress√£o linear com uma entrada e uma sa√≠da, usando \(\theta_0 = 3,75\) e \(\theta_1 = 6,78 \times 10^{-5}\)). A sele√ß√£o de modelo consiste em escolher o tipo de modelo e especificar completamente sua arquitetura. Treinar um modelo significa executar um algoritmo para encontrar os par√¢metros do modelo que o far√£o se ajustar melhor aos dados de treinamento e, esperan√ßosamente, fazer boas previs√µes em novos dados.

Agora o modelo se ajusta aos dados de treinamento o mais pr√≥ximo poss√≠vel (para um modelo linear), como voc√™ pode ver na Figura 1-20.

**Figura 1-20. O modelo linear que melhor se ajusta aos dados de treinamento**

Voc√™ est√° finalmente pronto para executar o modelo e fazer previs√µes. Por exemplo, digamos que voc√™ queira saber o qu√£o felizes s√£o os cipriotas, e os dados da OCDE n√£o t√™m a resposta. Felizmente, voc√™ pode usar seu modelo para fazer uma boa previs√£o: voc√™ consulta o PIB per capita de Chipre, encontra $37.655 e, em seguida, aplica seu modelo e descobre que a satisfa√ß√£o com a vida provavelmente est√° em torno de \(3,75 + 37.655 \times 6,78 \times 10^{-5} = 6,30\).

---

#### **Desafios Principais do Aprendizado de M√°quina**

Em resumo, como sua principal tarefa √© selecionar um modelo e trein√°-lo com alguns dados, as duas coisas que podem dar errado s√£o "modelo ruim" e "dados ruins". Vamos come√ßar com exemplos de dados ruins.

---

#### **Quantidade Insuficiente de Dados de Treinamento**

Para uma crian√ßa aprender o que √© uma ma√ß√£, basta apontar para uma ma√ß√£ e dizer "ma√ß√£" (possivelmente repetindo esse procedimento algumas vezes). Agora a crian√ßa √© capaz de reconhecer ma√ß√£s em todas as cores e formas. G√™nio.

O aprendizado de m√°quina ainda n√£o chegou l√°; √© preciso muita data para a maioria dos algoritmos de aprendizado de m√°quina funcionarem corretamente. Mesmo para problemas muito simples, voc√™ geralmente precisa de milhares de exemplos, e para problemas complexos, como reconhecimento de imagem ou fala, voc√™ pode precisar de milh√µes de exemplos (a menos que voc√™ possa reutilizar partes de um modelo existente).

---

#### **Dados de Treinamento N√£o Representativos**

Para generalizar bem, √© crucial que seus dados de treinamento sejam representativos dos novos casos para os quais voc√™ deseja generalizar. Isso √© verdade, quer voc√™ use aprendizado baseado em inst√¢ncia ou baseado em modelo.

Por exemplo, o conjunto de pa√≠ses que voc√™ usou anteriormente para treinar o modelo linear n√£o era perfeitamente representativo; ele n√£o continha nenhum pa√≠s com um PIB per capita inferior a $23.500 ou superior a $62.500. A Figura 1-22 mostra como os dados ficam quando voc√™ adiciona esses pa√≠ses.

Se voc√™ treinar um modelo linear nesses dados, obter√° a linha s√≥lida, enquanto o modelo antigo √© representado pela linha pontilhada. Como voc√™ pode ver, n√£o apenas a adi√ß√£o de alguns pa√≠ses ausentes altera significativamente o modelo, mas tamb√©m deixa claro que um modelo linear t√£o simples provavelmente nunca funcionar√° bem. Parece que pa√≠ses muito ricos n√£o s√£o mais felizes do que pa√≠ses moderadamente ricos (na verdade, eles parecem um pouco menos felizes!), e, inversamente, alguns pa√≠ses pobres parecem mais felizes do que muitos pa√≠ses ricos.

Ao usar um conjunto de treinamento n√£o representativo, voc√™ treinou um modelo que provavelmente n√£o far√° previs√µes precisas, especialmente para pa√≠ses muito pobres e muito ricos.

**Figura 1-22. Uma amostra de treinamento mais representativa**

√â crucial usar um conjunto de treinamento que seja representativo dos casos para os quais voc√™ deseja generalizar. Isso √© frequentemente mais dif√≠cil do que parece: se a amostra for muito pequena, voc√™ ter√° **ru√≠do de amostragem** (ou seja, dados n√£o representativos como resultado do acaso), mas mesmo amostras muito grandes podem ser n√£o representativas se o m√©todo de amostragem for falho. Isso √© chamado de **vi√©s de amostragem**.

---

#### **Exemplos de Vi√©s de Amostragem**

Talvez o exemplo mais famoso de vi√©s de amostragem tenha ocorrido durante a elei√ß√£o presidencial dos EUA em 1936, que op√¥s Landon a Roosevelt: o *Literary Digest* realizou uma pesquisa muito grande, enviando correspond√™ncia para cerca de 10 milh√µes de pessoas. Ele recebeu 2,4 milh√µes de respostas e previu com alta confian√ßa que Landon receberia 57% dos votos. Em vez disso, Roosevelt venceu com 62% dos votos. O erro estava no m√©todo de amostragem do *Literary Digest*:

1. Primeiro, para obter os endere√ßos para enviar as pesquisas, o *Literary Digest* usou listas telef√¥nicas, listas de assinantes de revistas, listas de membros de clubes e afins. Todas essas listas tendiam a favorecer pessoas mais ricas, que eram mais propensas a votar no Partido Republicano (da√≠ Landon).
2. Segundo, menos de 25% das pessoas que foram pesquisadas responderam. Isso introduziu um vi√©s de amostragem, potencialmente excluindo pessoas que n√£o se importavam muito com pol√≠tica, pessoas que n√£o gostavam do *Literary Digest* e outros grupos importantes. Isso √© um tipo especial de vi√©s de amostragem chamado **vi√©s de n√£o resposta**.

Aqui est√° outro exemplo: digamos que voc√™ queira construir um sistema para reconhecer v√≠deos de m√∫sica funk. Uma maneira de construir seu conjunto de treinamento √© pesquisar por "m√∫sica funk" no YouTube e usar os v√≠deos resultantes. Mas isso assume que o mecanismo de busca do YouTube retorna um conjunto de v√≠deos que s√£o representativos de todos os v√≠deos de m√∫sica funk no YouTube. Na realidade, os resultados da pesquisa provavelmente ser√£o tendenciosos em favor de artistas populares (e se voc√™ mora no Brasil, receber√° muitos v√≠deos de "funk carioca", que n√£o t√™m nada a ver com James Brown). Por outro lado, como mais voc√™ pode obter um grande conjunto de treinamento?

---

#### **Dados de Baixa Qualidade**

Obviamente, se seus dados de treinamento estiverem cheios de erros, outliers e ru√≠do (por exemplo, devido a medi√ß√µes de baixa qualidade), ser√° mais dif√≠cil para o sistema detectar os padr√µes subjacentes, ent√£o √© menos prov√°vel que seu sistema tenha um bom desempenho. Muitas vezes vale a pena gastar tempo limpando seus dados de treinamento. A verdade √© que a maioria dos cientistas de dados passa uma parte significativa de seu tempo fazendo exatamente isso. Aqui est√£o alguns exemplos de quando voc√™ pode querer limpar os dados de treinamento:

- Se algumas inst√¢ncias forem claramente outliers, pode ajudar simplesmente descart√°-las ou tentar corrigir os erros manualmente.
- Se algumas inst√¢ncias estiverem faltando alguns recursos (por exemplo, 5% dos seus clientes n√£o especificaram sua idade), voc√™ deve decidir se deseja ignorar esse atributo completamente, ignorar essas inst√¢ncias, preencher os valores ausentes (por exemplo, com a idade mediana) ou treinar um modelo com o recurso e outro sem ele.

---

#### **Recursos Irrelevantes**

Como diz o ditado: lixo entra, lixo sai. Seu sistema s√≥ ser√° capaz de aprender se os dados de treinamento contiverem recursos relevantes suficientes e n√£o muitos irrelevantes. Uma parte cr√≠tica do sucesso de um projeto de aprendizado de m√°quina √© criar um bom conjunto de recursos para treinar. Esse processo, chamado de **engenharia de recursos**, envolve as seguintes etapas:

1. **Sele√ß√£o de recursos**: selecionar os recursos mais √∫teis para treinar entre os recursos existentes.
2. **Extra√ß√£o de recursos**: combinar recursos existentes para produzir um mais √∫til ‚Äî como vimos anteriormente, algoritmos de redu√ß√£o de dimensionalidade podem ajudar.
3. **Cria√ß√£o de novos recursos**: coletar novos dados.

Agora que vimos muitos exemplos de dados ruins, vamos dar uma olhada em alguns exemplos de algoritmos ruins.

---

#### **Sobreajuste aos Dados de Treinamento**

Digamos que voc√™ est√° visitando um pa√≠s estrangeiro e o motorista de t√°xi tenta te enganar. Voc√™ pode ser tentado a dizer que **todos** os motoristas de t√°xi daquele pa√≠s s√£o ladr√µes. Generalizar demais √© algo que n√≥s, humanos, fazemos com frequ√™ncia, e, infelizmente, as m√°quinas podem cair na mesma armadilha se n√£o formos cuidadosos. No aprendizado de m√°quina, isso √© chamado de **sobreajuste**: significa que o modelo tem um bom desempenho nos dados de treinamento, mas n√£o generaliza bem.

A Figura 1-23 mostra um exemplo de um modelo polinomial de alto grau de satisfa√ß√£o com a vida que se ajusta excessivamente aos dados de treinamento. Embora ele tenha um desempenho muito melhor nos dados de treinamento do que o modelo linear simples, voc√™ realmente confiaria em suas previs√µes?

**Figura 1-23. Sobreajuste aos dados de treinamento**

Modelos complexos, como redes neurais profundas, podem detectar padr√µes sutis nos dados, mas se o conjunto de treinamento for ruidoso ou muito pequeno, o que introduz ru√≠do de amostragem, o modelo provavelmente detectar√° padr√µes no pr√≥prio ru√≠do (como no exemplo do motorista de t√°xi). Obviamente, esses padr√µes n√£o generalizar√£o para novas inst√¢ncias. Por exemplo, digamos que voc√™ alimente seu modelo de satisfa√ß√£o com a vida com muitos atributos adicionais, incluindo alguns irrelevantes, como o nome do pa√≠s. Nesse caso, um modelo complexo pode detectar padr√µes como o fato de que todos os pa√≠ses no conjunto de treinamento com um "w" no nome t√™m uma satisfa√ß√£o com a vida maior que 7: Nova Zel√¢ndia (7,3), Noruega (7,6), Su√©cia (7,3) e Su√≠√ßa (7,5). Qu√£o confiante voc√™ est√° de que a regra do "w-satisfa√ß√£o" generaliza para Ruanda ou Zimb√°bue? Obviamente, esse padr√£o ocorreu nos dados de treinamento por puro acaso, mas o modelo n√£o tem como saber se um padr√£o √© real ou simplesmente o resultado do ru√≠do nos dados.

**AVISO**  
O sobreajuste ocorre quando o modelo √© muito complexo em rela√ß√£o √† quantidade e ao ru√≠do dos dados de treinamento. Aqui est√£o algumas solu√ß√µes poss√≠veis:

- **Simplifique o modelo** selecionando um com menos par√¢metros (por exemplo, um modelo linear em vez de um modelo polinomial de alto grau), reduzindo o n√∫mero de atributos nos dados de treinamento ou restringindo o modelo.
- **Colete mais dados de treinamento**.
- **Reduza o ru√≠do nos dados de treinamento** (por exemplo, corrija erros nos dados e remova outliers).

Restringir um modelo para torn√°-lo mais simples e reduzir o risco de sobreajuste √© chamado de **regulariza√ß√£o**. Por exemplo, o modelo linear que definimos anteriormente tem dois par√¢metros, \(\theta_0\) e \(\theta_1\). Isso d√° ao algoritmo de aprendizado dois **graus de liberdade** para ajustar o modelo aos dados de treinamento: ele pode ajustar tanto a altura (\(\theta_0\)) quanto a inclina√ß√£o (\(\theta_1\)) da linha. Se for√ßarmos \(\theta_1 = 0\), o algoritmo ter√° apenas um grau de liberdade e ter√° muito mais dificuldade para ajustar os dados corretamente: tudo o que ele poderia fazer √© mover a linha para cima ou para baixo para chegar o mais pr√≥ximo poss√≠vel das inst√¢ncias de treinamento, ent√£o ele acabaria em torno da m√©dia. Um modelo muito simples, de fato! Se permitirmos que o algoritmo modifique \(\theta_1\), mas o for√ßarmos a mant√™-lo pequeno, o algoritmo de aprendizado ter√° efetivamente algo entre um e dois graus de liberdade. Ele produzir√° um modelo mais simples do que um com dois graus de liberdade, mas mais complexo do que um com apenas um. Voc√™ quer encontrar o equil√≠brio certo entre ajustar os dados de treinamento perfeitamente e manter o modelo simples o suficiente para garantir que ele generalize bem.

A Figura 1-24 mostra tr√™s modelos. A linha pontilhada representa o modelo original que foi treinado nos pa√≠ses representados como c√≠rculos (sem os pa√≠ses representados como quadrados), a linha s√≥lida √© nosso segundo modelo treinado com todos os pa√≠ses (c√≠rculos e quadrados), e a linha tracejada √© um modelo treinado com os mesmos dados do primeiro modelo, mas com uma restri√ß√£o de regulariza√ß√£o. Voc√™ pode ver que a regulariza√ß√£o for√ßou o modelo a ter uma inclina√ß√£o menor: esse modelo n√£o se ajusta t√£o bem aos dados de treinamento (c√≠rculos) quanto o primeiro modelo, mas na verdade generaliza melhor para novos exemplos que ele n√£o viu durante o treinamento (quadrados).

**Figura 1-24. A regulariza√ß√£o reduz o risco de sobreajuste**

A quantidade de regulariza√ß√£o a ser aplicada durante o aprendizado pode ser controlada por um **hiperpar√¢metro**. Um hiperpar√¢metro √© um par√¢metro de um algoritmo de aprendizado (n√£o do modelo). Como tal, ele n√£o √© afetado pelo algoritmo de aprendizado em si; ele deve ser definido antes do treinamento e permanece constante durante o treinamento. Se voc√™ definir o hiperpar√¢metro de regulariza√ß√£o para um valor muito alto, obter√° um modelo quase plano (uma inclina√ß√£o pr√≥xima de zero); o algoritmo de aprendizado quase certamente n√£o se ajustar√° excessivamente aos dados de treinamento, mas ser√° menos prov√°vel que encontre uma boa solu√ß√£o. Ajustar hiperpar√¢metros √© uma parte importante da constru√ß√£o de um sistema de aprendizado de m√°quina (voc√™ ver√° um exemplo detalhado no pr√≥ximo cap√≠tulo).

---

#### **Subajuste aos Dados de Treinamento**

Como voc√™ pode imaginar, o **subajuste** √© o oposto do sobreajuste: ocorre quando seu modelo √© muito simples para aprender a estrutura subjacente dos dados. Por exemplo, um modelo linear de satisfa√ß√£o com a vida √© propenso a subajuste; a realidade √© simplesmente mais complexa do que o modelo, ent√£o suas previs√µes s√£o inevitavelmente imprecisas, mesmo nos exemplos de treinamento.

Aqui est√£o as principais op√ß√µes para corrigir esse problema:

- **Selecione um modelo mais poderoso**, com mais par√¢metros.
- **Alimente melhores recursos ao algoritmo de aprendizado** (engenharia de recursos).
- **Reduza as restri√ß√µes no modelo** (por exemplo, reduzindo o hiperpar√¢metro de regulariza√ß√£o).

---

#### **Recapitulando**

Agora voc√™ j√° sabe muito sobre aprendizado de m√°quina. No entanto, passamos por tantos conceitos que voc√™ pode estar se sentindo um pouco perdido, ent√£o vamos recapitular e olhar para o quadro geral:

- **Aprendizado de m√°quina** √© sobre fazer m√°quinas melhorarem em alguma tarefa aprendendo com dados, em vez de ter que codificar regras explicitamente.
- Existem muitos tipos diferentes de sistemas de ML: supervisionados ou n√£o, em lote ou online, baseados em inst√¢ncia ou baseados em modelo.
- Em um projeto de ML, voc√™ coleta dados em um conjunto de treinamento e os alimenta a um algoritmo de aprendizado. Se o algoritmo for baseado em modelo, ele ajusta alguns par√¢metros para ajustar o modelo ao conjunto de treinamento (ou seja, para fazer boas previs√µes no pr√≥prio conjunto de treinamento) e, em seguida, espera-se que ele fa√ßa boas previs√µes em novos casos tamb√©m. Se o algoritmo for baseado em inst√¢ncia, ele simplesmente aprende os exemplos de cor e generaliza para novas inst√¢ncias usando uma medida de similaridade para compar√°-las √†s inst√¢ncias aprendidas.
- O sistema n√£o ter√° um bom desempenho se o conjunto de treinamento for muito pequeno, ou se os dados n√£o forem representativos, forem ruidosos ou estiverem polu√≠dos com recursos irrelevantes (lixo entra, lixo sai). Por fim, seu modelo n√£o deve ser nem muito simples (caso em que ele subajustar√°) nem muito complexo (caso em que ele sobreajustar√°).

H√° apenas um √∫ltimo t√≥pico importante a ser abordado: depois de treinar um modelo, voc√™ n√£o quer apenas "esperar" que ele generalize para novos casos. Voc√™ quer avali√°-lo e ajust√°-lo, se necess√°rio. Vamos ver como fazer isso.

---

#### **Testando e Validando**

A √∫nica maneira de saber qu√£o bem um modelo generalizar√° para novos casos √© realmente test√°-lo em novos casos. Uma maneira de fazer isso √© colocar seu modelo em produ√ß√£o e monitorar seu desempenho. Isso funciona bem, mas se seu modelo for horrivelmente ruim, seus usu√°rios reclamar√£o ‚Äî n√£o √© a melhor ideia.

Uma op√ß√£o melhor √© dividir seus dados em dois conjuntos: o **conjunto de treinamento** e o **conjunto de teste**. Como os nomes sugerem, voc√™ treina seu modelo usando o conjunto de treinamento e o testa usando o conjunto de teste. A taxa de erro em novos casos √© chamada de **erro de generaliza√ß√£o** (ou **erro fora da amostra**), e, ao avaliar seu modelo no conjunto de teste, voc√™ obt√©m uma estimativa desse erro. Esse valor diz o qu√£o bem seu modelo provavelmente se sair√° em inst√¢ncias que nunca viu antes.

Se o erro de treinamento for baixo (ou seja, seu modelo comete poucos erros no conjunto de treinamento), mas o erro de generaliza√ß√£o for alto, isso significa que seu modelo est√° sobreajustando os dados de treinamento.

**DICA**  
√â comum usar 80% dos dados para treinamento e **reservar** 20% para teste. No entanto, isso depende do tamanho do conjunto de dados: se ele contiver 10 milh√µes de inst√¢ncias, reservar 1% significa que seu conjunto de teste ter√° 100.000 inst√¢ncias, provavelmente mais do que suficiente para obter uma boa estimativa do erro de generaliza√ß√£o.

---

#### **Ajuste de Hiperpar√¢metros e Sele√ß√£o de Modelos**

Avaliar um modelo √© simples o suficiente: basta usar um conjunto de teste. Mas suponha que voc√™ esteja hesitando entre dois tipos de modelos (digamos, um modelo linear e um modelo polinomial): como voc√™ pode decidir entre eles? Uma op√ß√£o √© treinar ambos e comparar o qu√£o bem eles generalizam usando o conjunto de teste.

Agora suponha que o modelo linear generalize melhor, mas voc√™ deseja aplicar alguma regulariza√ß√£o para evitar o sobreajuste. A quest√£o √©: como voc√™ escolhe o valor do hiperpar√¢metro de regulariza√ß√£o? Uma op√ß√£o √© treinar 100 modelos diferentes usando 100 valores diferentes para esse hiperpar√¢metro. Suponha que voc√™ encontre o melhor valor de hiperpar√¢metro que produz um modelo com o menor erro de generaliza√ß√£o ‚Äî digamos, apenas 5% de erro. Voc√™ lan√ßa esse modelo em produ√ß√£o, mas, infelizmente, ele n√£o tem o desempenho esperado e produz 15% de erros. O que aconteceu?

O problema √© que voc√™ mediu o erro de generaliza√ß√£o v√°rias vezes no conjunto de teste e adaptou o modelo e os hiperpar√¢metros para produzir o melhor modelo para aquele conjunto espec√≠fico. Isso significa que o modelo provavelmente n√£o ter√° um bom desempenho em novos dados.

Uma solu√ß√£o comum para esse problema √© chamada de **valida√ß√£o holdout** (Figura 1-25): voc√™ simplesmente reserva parte do conjunto de treinamento para avaliar v√°rios modelos candidatos e selecionar o melhor. O novo conjunto reservado √© chamado de **conjunto de valida√ß√£o** (ou conjunto de desenvolvimento, ou dev set). Mais especificamente, voc√™ treina v√°rios modelos com v√°rios hiperpar√¢metros no conjunto de treinamento reduzido (ou seja, o conjunto de treinamento completo menos o conjunto de valida√ß√£o) e seleciona o modelo que tem o melhor desempenho no conjunto de valida√ß√£o. Ap√≥s esse processo de valida√ß√£o holdout, voc√™ treina o melhor modelo no conjunto de treinamento completo (incluindo o conjunto de valida√ß√£o), e isso lhe d√° o modelo final. Por fim, voc√™ avalia esse modelo final no conjunto de teste para obter uma estimativa do erro de generaliza√ß√£o.

**Figura 1-25. Sele√ß√£o de modelo usando valida√ß√£o holdout**

Essa solu√ß√£o geralmente funciona muito bem. No entanto, se o conjunto de valida√ß√£o for muito pequeno, as avalia√ß√µes do modelo ser√£o imprecisas: voc√™ pode acabar selecionando um modelo sub√≥timo por engano. Por outro lado, se o conjunto de valida√ß√£o for muito grande, o conjunto de treinamento restante ser√° muito menor do que o conjunto de treinamento completo. Por que isso √© ruim? Bem, como o modelo final ser√° treinado no conjunto de treinamento completo, n√£o √© ideal comparar modelos candidatos treinados em um conjunto de treinamento muito menor. Seria como selecionar o corredor mais r√°pido para participar de uma maratona. Uma maneira de resolver esse problema √© realizar **valida√ß√£o cruzada repetida**, usando muitos pequenos conjuntos de valida√ß√£o. Cada modelo √© avaliado uma vez por conjunto de valida√ß√£o depois de ser treinado no restante dos dados. Ao calcular a m√©dia de todas as avalia√ß√µes de um modelo, voc√™ obt√©m uma medida muito mais precisa de seu desempenho. No entanto, h√° uma desvantagem: o tempo de treinamento √© multiplicado pelo n√∫mero de conjuntos de valida√ß√£o.

---

#### **Desajuste de Dados**

Em alguns casos, √© f√°cil obter uma grande quantidade de dados para treinamento, mas esses dados provavelmente n√£o ser√£o perfeitamente representativos dos dados que ser√£o usados em produ√ß√£o. Por exemplo, suponha que voc√™ queira criar um aplicativo m√≥vel para tirar fotos de flores e determinar automaticamente suas esp√©cies. Voc√™ pode facilmente baixar milh√µes de fotos de flores na web, mas elas n√£o ser√£o perfeitamente representativas das fotos que realmente ser√£o tiradas usando o aplicativo em um dispositivo m√≥vel. Talvez voc√™ tenha apenas 1.000 fotos representativas (ou seja, realmente tiradas com o aplicativo).

Nesse caso, a regra mais importante a lembrar √© que tanto o conjunto de valida√ß√£o quanto o conjunto de teste devem ser o mais representativos poss√≠vel dos dados que voc√™ espera usar em produ√ß√£o, ent√£o eles devem ser compostos exclusivamente de fotos representativas: voc√™ pode embaralh√°-las e colocar metade no conjunto de valida√ß√£o e metade no conjunto de teste (garantindo que nenhuma duplicata ou quase-duplicata acabe em ambos os conjuntos). Depois de treinar seu modelo nas fotos da web, se voc√™ observar que o desempenho do modelo no conjunto de valida√ß√£o √© decepcionante, voc√™ n√£o saber√° se isso ocorre porque seu modelo sobreajustou o conjunto de treinamento ou se √© apenas devido ao desajuste entre as fotos da web e as fotos do aplicativo m√≥vel.

Uma solu√ß√£o √© reservar algumas das fotos de treinamento (da web) em outro conjunto que Andrew Ng chamou de **conjunto train-dev** (Figura 1-26). Depois que o modelo for treinado (no conjunto de treinamento, n√£o no conjunto train-dev), voc√™ pode avali√°-lo no conjunto train-dev. Se o modelo tiver um desempenho ruim, ele deve ter sobreajustado o conjunto de treinamento, ent√£o voc√™ deve tentar simplificar ou regularizar o modelo, obter mais dados de treinamento e limpar os dados de treinamento. Mas se ele tiver um bom desempenho no conjunto train-dev, voc√™ pode avaliar o modelo no conjunto de valida√ß√£o. Se ele tiver um desempenho ruim, o problema deve estar vindo do desajuste de dados. Voc√™ pode tentar resolver esse problema pr√©-processando as imagens da web para que pare√ßam mais com as fotos que ser√£o tiradas pelo aplicativo m√≥vel e, em seguida, retreinar o modelo. Uma vez que voc√™ tenha um modelo que tenha um bom desempenho tanto no conjunto train-dev quanto no conjunto de valida√ß√£o, voc√™ pode avali√°-lo uma √∫ltima vez no conjunto de teste para saber o qu√£o bem ele provavelmente se sair√° em produ√ß√£o.

**Figura 1-26. Quando os dados reais s√£o escassos (direita), voc√™ pode usar dados abundantes semelhantes (esquerda) para treinamento e reservar alguns deles em um conjunto train-dev para avaliar o sobreajuste; os dados reais s√£o ent√£o usados para avaliar o desajuste de dados (conjunto de valida√ß√£o) e o desempenho do modelo final (conjunto de teste)**

---

#### **Teorema do Almo√ßo Gr√°tis**

Um modelo √© uma representa√ß√£o simplificada dos dados. As simplifica√ß√µes destinam-se a descartar os detalhes sup√©rfluos que provavelmente n√£o generalizar√£o para novas inst√¢ncias. Quando voc√™ seleciona um tipo espec√≠fico de modelo, est√° implicitamente fazendo suposi√ß√µes sobre os dados. Por exemplo, se voc√™ escolher um modelo linear, est√° implicitamente assumindo que os dados s√£o fundamentalmente lineares e que a dist√¢ncia entre as inst√¢ncias e a linha reta √© apenas ru√≠do, que pode ser ignorado com seguran√ßa.

Em um famoso artigo de 1996, David Wolpert demonstrou que, se voc√™ n√£o fizer absolutamente nenhuma suposi√ß√£o sobre os dados, n√£o h√° raz√£o para preferir um modelo sobre qualquer outro. Isso √© chamado de **Teorema do Almo√ßo Gr√°tis (NFL)**. Para alguns conjuntos de dados, o melhor modelo √© um modelo linear, enquanto para outros √© uma rede neural. N√£o h√° modelo que seja **a priori** garantido para funcionar melhor (da√≠ o nome do teorema). A √∫nica maneira de saber com certeza qual modelo √© o melhor √© avaliar todos eles. Como isso n√£o √© poss√≠vel, na pr√°tica voc√™ faz algumas suposi√ß√µes razo√°veis sobre os dados e avalia apenas alguns modelos razo√°veis. Por exemplo, para tarefas simples, voc√™ pode avaliar modelos lineares com v√°rios n√≠veis de regulariza√ß√£o, e para um problema complexo, voc√™ pode avaliar v√°rias redes neurais.

---

#### **Exerc√≠cios**

Neste cap√≠tulo, cobrimos alguns dos conceitos mais importantes do aprendizado de m√°quina. Nos pr√≥ximos cap√≠tulos, mergulharemos mais fundo e escreveremos mais c√≥digo, mas antes disso, certifique-se de que voc√™ pode responder √†s seguintes perguntas:

1. Como voc√™ definiria aprendizado de m√°quina?
2. Voc√™ pode nomear quatro tipos de aplica√ß√µes onde ele se destaca?
3. O que √© um conjunto de treinamento rotulado?
4. Quais s√£o as duas tarefas supervisionadas mais comuns?
5. Voc√™ pode nomear quatro tarefas n√£o supervisionadas comuns?
6. Que tipo de algoritmo voc√™ usaria para permitir que um rob√¥ andasse em v√°rios terrenos desconhecidos?
7. Que tipo de algoritmo voc√™ usaria para segmentar seus clientes em v√°rios grupos?
8. Voc√™ enquadraria o problema de detec√ß√£o de spam como um problema de aprendizado supervisionado ou n√£o supervisionado?
9. O que √© um sistema de aprendizado online?
10. O que √© aprendizado fora do n√∫cleo?
11. Que tipo de algoritmo depende de uma medida de similaridade para fazer previs√µes?
12. Qual √© a diferen√ßa entre um par√¢metro do modelo e um hiperpar√¢metro do modelo?
13. O que os algoritmos baseados em modelo procuram? Qual √© a estrat√©gia mais comum que eles usam para ter sucesso? Como eles fazem previs√µes?
14. Voc√™ pode nomear quatro dos principais desafios no aprendizado de m√°quina?
15. Se o seu modelo tiver um √≥timo desempenho nos dados de treinamento, mas generalizar mal para novas inst√¢ncias, o que est√° acontecendo? Voc√™ pode nomear tr√™s solu√ß√µes poss√≠veis?
16. O que √© um conjunto de teste e por que voc√™ o usaria?
17. Qual √© o prop√≥sito de um conjunto de valida√ß√£o?
18. O que √© um conjunto train-dev, quando voc√™ precisa dele e como o usa?
19. O que pode dar errado se voc√™ ajustar hiperpar√¢metros usando o conjunto de teste?

As solu√ß√µes para esses exerc√≠cios est√£o dispon√≠veis no final do notebook deste cap√≠tulo, em https://homl.info/colab3.

---

#### **Notas de Rodap√©**

1. Curiosidade: esse nome estranho √© um termo estat√≠stico introduzido por Francis Galton enquanto ele estudava o fato de que os filhos de pessoas altas tendem a ser mais baixos que seus pais. Como os filhos eram mais baixos, ele chamou isso de **regress√£o √† m√©dia**. Esse nome foi ent√£o aplicado aos m√©todos que ele usou para analisar correla√ß√µes entre vari√°veis.
2. Observe como os animais est√£o bem separados dos ve√≠culos e como os cavalos est√£o pr√≥ximos dos cervos, mas longe dos p√°ssaros. Figura reproduzida com permiss√£o de Richard Socher et al., "Zero-Shot Learning Through Cross-Modal Transfer", *Proceedings of the 26th International Conference on Neural Information Processing Systems* 1 (2013): 935‚Äì943.
3. Isso √© quando o sistema funciona perfeitamente. Na pr√°tica, ele frequentemente cria alguns clusters por pessoa e, √†s vezes, mistura duas pessoas que se parecem, ent√£o voc√™ pode precisar fornecer alguns r√≥tulos por pessoa e limpar manualmente alguns clusters.
4. Por conven√ß√£o, a letra grega \(\theta\) (theta) √© frequentemente usada para representar par√¢metros do modelo.
5. Tudo bem se voc√™ n√£o entender todo o c√≥digo ainda; apresentarei o Scikit-Learn nos pr√≥ximos cap√≠tulos.
6. Por exemplo, saber se deve escrever "to", "two" ou "too", dependendo do contexto.
7. Peter Norvig et al., "The Unreasonable Effectiveness of Data", *IEEE Intelligent Systems* 24, no. 2 (2009): 8‚Äì12.
8. Figura reproduzida com permiss√£o de Michele Banko e Eric Brill, "Scaling to Very Very Large Corpora for Natural Language Disambiguation", *Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics* (2001): 26‚Äì33.
9. David Wolpert, "The Lack of A Priori Distinctions Between Learning Algorithms", *Neural Computation* 8, no. 7 (1996): 1341‚Äì1390.

---

Se precisar de mais alguma coisa, estou √† disposi√ß√£o! üòä





